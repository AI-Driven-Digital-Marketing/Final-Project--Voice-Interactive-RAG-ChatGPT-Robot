{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Question Answering with local persistence\n",
    "\n",
    "An example of using Chroma DB and LangChain to do question answering over documents, with a locally persisted database. \n",
    "You can store embeddings and documents, then use them again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.3.21-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 2.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting sentence-transformers>=2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting duckdb>=0.7.1\n",
      "  Downloading duckdb-0.7.1-cp39-cp39-macosx_10_9_x86_64.whl (14.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.6 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.28 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.22.4)\n",
      "Collecting posthog>=2.4.0\n",
      "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Collecting hnswlib>=0.7\n",
      "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.21.1)\n",
      "Collecting clickhouse-connect>=0.5.7\n",
      "  Downloading clickhouse_connect-0.5.21-cp39-cp39-macosx_10_9_x86_64.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fastapi>=0.85.1 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.95.1)\n",
      "Requirement already satisfied: pandas>=1.3 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.5.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.10.4)\n",
      "Requirement already satisfied: certifi in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
      "Collecting lz4\n",
      "  Downloading lz4-4.3.2-cp39-cp39-macosx_10_9_x86_64.whl (254 kB)\n",
      "\u001b[K     |████████████████████████████████| 254 kB 23.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2021.3)\n",
      "Collecting zstandard\n",
      "  Downloading zstandard-0.21.0-cp39-cp39-macosx_10_9_x86_64.whl (473 kB)\n",
      "\u001b[K     |████████████████████████████████| 473 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.26 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.7)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.15.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.24.2)\n",
      "Requirement already satisfied: scipy in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.7.1)\n",
      "Requirement already satisfied: nltk in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (3.6.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.98-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 17.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.4)\n",
      "Requirement already satisfied: filelock in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.2.0)\n",
      "Requirement already satisfied: sympy in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.9)\n",
      "Requirement already satisfied: jinja2 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.11.3)\n",
      "Requirement already satisfied: networkx in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2023.3.23)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.0.3)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.5.0-cp39-cp39-macosx_10_9_x86_64.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-11.0.2-cp39-cp39-macosx_10_9_x86_64.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.17.0-cp39-cp39-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.19.0-cp37-abi3-macosx_10_7_x86_64.whl (405 kB)\n",
      "\u001b[K     |████████████████████████████████| 405 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.1.1)\n",
      "Requirement already satisfied: joblib in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/raydenx/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.5.0)\n",
      "Building wheels for collected packages: hnswlib, sentence-transformers\n",
      "  Building wheel for hnswlib (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp39-cp39-macosx_10_9_x86_64.whl size=180033 sha256=b08086492aad505c82264b25ca8905da462c55b4b8b53da2f7a4cfd946c64ba4\n",
      "  Stored in directory: /Users/raydenx/Library/Caches/pip/wheels/ba/26/61/fface6c407f56418b3140cd7645917f20ba6b27d4e32b2bd20\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=eab5fc1a85f5e4abbff5966bc2edae3b2b450edb3321c41b323d9f96eb4601fe\n",
      "  Stored in directory: /Users/raydenx/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built hnswlib sentence-transformers\n",
      "Installing collected packages: zstandard, websockets, watchfiles, uvloop, sentencepiece, python-dotenv, lz4, httptools, sentence-transformers, posthog, hnswlib, duckdb, clickhouse-connect, chromadb\n",
      "Successfully installed chromadb-0.3.21 clickhouse-connect-0.5.21 duckdb-0.7.1 hnswlib-0.7.0 httptools-0.5.0 lz4-4.3.2 posthog-3.0.1 python-dotenv-1.0.0 sentence-transformers-2.2.2 sentencepiece-0.1.98 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.2 zstandard-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process documents\n",
    "\n",
    "Load documents to do question answering over. If you want to do this over your documents, this is the section you should replace.\n",
    "\n",
    "Next we split documents into small chunks. This is so we can find the most relevant chunks for a query and pass only those into the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, UnstructuredURLLoader, OnlinePDFLoader, PDFMinerLoader,BSHTMLLoader,SeleniumURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = [\"https://www.nature.com/articles/s41565-023-01366-7\",\n",
    "       'https://www.nature.com/articles/s43586-023-00211-4',\n",
    "       'https://www.nature.com/articles/s44161-023-00232-y',\n",
    "       'https://www.nature.com/articles/s42004-023-00852-2',\n",
    "       'https://www.nature.com/articles/s41467-022-32349-2',\n",
    "       'https://www.nature.com/articles/s44161-023-00232-y',\n",
    "       'https://www.nature.com/articles/s41565-023-01382-7',\n",
    "       'https://www.nature.com/articles/s44222-023-00035-7'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_loader = SeleniumURLLoader(urls=url)\n",
    "urldata = url_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "# Load and process the text\n",
    "loader1 = OnlinePDFLoader(\"https://downloads.hindawi.com/journals/bmri/2022/2426960.pdf\")\n",
    "documents = loader1.load()+urldata\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize PeristedChromaDB\n",
    "\n",
    "Create embeddings for each chunk and insert into the Chroma vector database. The `persist_directory` argument tells ChromaDB where to store the database when it's persisted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "embedding = OpenAIEmbeddings( openai_api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(documents=texts, embedding=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding End！Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist the Database\n",
    "In a notebook, we should call `persist()` to ensure the embeddings are written to disk.\n",
    "This isn't necessary in a script - the database will be automatically persisted when the client object is destroyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Database from disk, and create the chain\n",
    "Be sure to pass the same `persist_directory` and `embedding_function` as you did when you instantiated the database. Initialize the chain we will use for question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n",
      "/Users/raydenx/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/retrieval_qa/base.py:186: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "qa = VectorDBQA.from_chain_type(llm=OpenAI(openai_api_key=OPENAI_API_KEY), chain_type=\"stuff\", vectorstore=vectordb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions!\n",
    "\n",
    "Now we can use the chain to ask questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' AI nanomedicine is the utilization of artificial intelligence (AI) and nanotechnology to improve the delivery of drugs, diagnostics, and treatments for cancer and cardiovascular diseases.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the AI nanomedicine?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "When you're done with the database, you can delete it from disk. You can delete the specific collection you're working with (if you have several), or delete the entire database by nuking the persistence directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisting DB to disk, putting it in the save folder db\n"
     ]
    }
   ],
   "source": [
    "# # To cleanup, you can delete the collection\n",
    "# vectordb.delete_collection()\n",
    "# vectordb.persist()\n",
    "\n",
    "# # Or just nuke the persist directory\n",
    "# !rm -rf db/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "c909e91d0cd7642213937968dfc91c71973575965f56cdcabb1e0b29abe5f7fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
